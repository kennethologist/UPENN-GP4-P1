{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import dotenv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance\n",
    "import alpaca_trade_api as alpaca_api\n",
    "import krakenex\n",
    "import pykrakenapi\n",
    "import pandas_montecarlo\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_portfolios_generator(tickers, n):\n",
    "    random_portfolios = pd.DataFrame({'ticker':tickers})\n",
    "    for n in range(0, n):\n",
    "        random_portfolios[f'random weights {n+1}'] = [np.random.rand() for i in range (0, len(tickers))]\n",
    "        random_portfolios[f'random weights {n+1}'] = random_portfolios[f'random weights {n+1}'] / sum(random_portfolios[f'random weights {n+1}'])\n",
    "    return(random_portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_api_key = os.getenv('alpaca_api_key')\n",
    "alpaca_secret_key = os.getenv('alpaca_secret_key')\n",
    "kraken_api_key = os.getenv('kraken_api_key')\n",
    "kraken_secret_key = os.getenv('kraken_secret_key')\n",
    "\n",
    "print(type(alpaca_api_key))\n",
    "print(type(alpaca_secret_key))\n",
    "print(type(kraken_api_key))\n",
    "print(type(kraken_secret_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "#sp_500_table = table[0]\n",
    "#sp_500_list = sp_500_table['Symbol'].to_list()\n",
    "#sp_500 = yfinance.download(sp_500_list, '2015-12-01')\n",
    "#sp_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca = alpaca_api.REST(alpaca_api_key, alpaca_secret_key, api_version=\"v2\")\n",
    "\n",
    "faangmula_tickers =  ['AAPL',  'ABNB', 'AMZN', 'FB', 'GOOG', 'LYFT', 'MSFT', 'NFLX', 'UBER']\n",
    "start = pd.Timestamp('2015-12-01', tz='America/New_York').isoformat()\n",
    "\n",
    "faangmula_original = alpaca.get_bars(faangmula_tickers, alpaca_api.TimeFrame.Day, start = start).df\n",
    "faangmula_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faangmula = faangmula_original.drop(['open', 'high', 'low', 'volume', 'trade_count', 'vwap'], axis = 1).pivot(columns = 'symbol')\n",
    "faangmula.index = faangmula.index.date\n",
    "faangmula.columns = faangmula_tickers\n",
    "faangmula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market capitalization data in trillions of dollars, sourced from Trading View on April 6, 2022.\n",
    "\n",
    "faangmula_caps_list = [2.804, 0.105855, 1.616, 0.60781, 1.81, 0.012576, 2.245, 0.163534, 0.065299]\n",
    "faangmula_cap_portfolio = pd.DataFrame({'tickers':faangmula_tickers, 'market cap weights':[market_cap / sum(faangmula_caps_list) for market_cap in faangmula_caps_list]}).set_index('tickers')\n",
    "faangmula_cap_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faangmula_cap_daily_returns = faangmula.pct_change().fillna(0.0).dot(faangmula_cap_portfolio)\n",
    "faangmula_cap_daily_returns.columns = ['faangmula index']\n",
    "faangmula_cap_daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_faangmula_portfolios = random_portfolios_generator(faangmula_tickers, 1000)\n",
    "random_faangmula_portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_faangmula_daily_returns_list = []\n",
    "for n in range(0, (len(random_faangmula_portfolios.columns) - 1)):\n",
    "        random_faangmula_daily_returns_list.append(faangmula.pct_change().fillna(0.0).dot(list(random_faangmula_portfolios.loc[:, f'random weights {n + 1}'])))\n",
    "\n",
    "random_faangmula_daily_returns = pd.concat(random_faangmula_daily_returns_list, axis = 'columns', join = 'inner')\n",
    "\n",
    "for n in range(0, (len(random_faangmula_portfolios.columns) - 1)):\n",
    "        random_faangmula_daily_returns = random_faangmula_daily_returns.rename(columns = {n: f'random faangmula portfolio {n + 1}'})\n",
    "\n",
    "random_faangmula_daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faangmula_daily_returns = pd.concat([faangmula_cap_daily_returns, random_faangmula_daily_returns], axis = 1, join = 'inner')\n",
    "faangmula_daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faangmula_correlations = faangmula_daily_returns.corr()\n",
    "faangmula_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_correlation_faangmula_original = faangmula_correlations.sort_values('faangmula index')['faangmula index'].head(10).reset_index().rename({'index': 'portfolio', 'faangmula index': 'faangmula index correlation'}, axis = 1)\n",
    "low_correlation_faangmula_original.loc[len(low_correlation_faangmula_original.values)] = ['faangmula index', 1.0]\n",
    "low_correlation_faangmula_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = []\n",
    "covariances = []\n",
    "for portfolio in low_correlation_faangmula_original['portfolio']:\n",
    "    variance = faangmula_daily_returns[f'{portfolio}'].var()\n",
    "    covariance = faangmula_daily_returns[f'{portfolio}'].cov(faangmula_daily_returns['faangmula index'])\n",
    "    variances.append(variance)\n",
    "    covariances.append(covariance)\n",
    "\n",
    "lc_intermediate_1 = pd.concat([low_correlation_faangmula_original, pd.DataFrame(variances)], axis = 1).rename({0: 'portfolio variance'}, axis = 1)\n",
    "lc_intermediate_2 = pd.concat([lc_intermediate_1, pd.DataFrame(covariances)], axis = 1).rename({0: 'faangmula index covariance'}, axis = 1)\n",
    "lc_intermediate_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = []\n",
    "for portfolio in low_correlation_faangmula_original['portfolio']:\n",
    "    beta = lc_intermediate_2.set_index('portfolio').at[f'{portfolio}', 'faangmula index covariance'] / lc_intermediate_2.set_index('portfolio').at[f'{portfolio}', 'portfolio variance']\n",
    "    betas.append(beta)\n",
    "\n",
    "lc_intermediate_3 = pd.concat([lc_intermediate_2, pd.DataFrame(betas)], axis = 1).rename({0: 'faangmula index beta'}, axis = 1)\n",
    "lc_intermediate_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_returns = []\n",
    "for portfolio in low_correlation_faangmula_original['portfolio']:\n",
    "    average_return = faangmula_daily_returns[f'{portfolio}'].mean()\n",
    "    average_returns.append(average_return)\n",
    "\n",
    "lc_intermediate_4 = pd.concat([lc_intermediate_3, pd.DataFrame(average_returns)], axis = 1).rename({0: 'average daily return'}, axis = 1)\n",
    "lc_intermediate_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = []\n",
    "for portfolio in low_correlation_faangmula_original['portfolio']:\n",
    "    std = faangmula_daily_returns[f'{portfolio}'].std()\n",
    "    stds.append(std)\n",
    "\n",
    "lc_intermediate_5 = pd.concat([lc_intermediate_4, pd.DataFrame(stds)], axis = 1).rename({0: 'standard deviation'}, axis = 1)\n",
    "lc_intermediate_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_sharpes = []\n",
    "for portfolio in low_correlation_faangmula_original['portfolio']:\n",
    "    zero_sharpe = (lc_intermediate_5.set_index('portfolio').at[f'{portfolio}', 'average daily return'] - 0) / lc_intermediate_5.set_index('portfolio').at[f'{portfolio}', 'standard deviation']\n",
    "    zero_sharpes.append(zero_sharpe)\n",
    "\n",
    "lc_intermediate_6 = pd.concat([lc_intermediate_5, pd.DataFrame(zero_sharpes)], axis = 1).rename({0: 'zero sharpe ratio'}, axis = 1)\n",
    "lc_intermediate_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faangmula_sharpes = []\n",
    "for portfolio in low_correlation_faangmula_original['portfolio']:\n",
    "    faangmula_sharpe = (lc_intermediate_6.set_index('portfolio').at[f'{portfolio}', 'average daily return'] - lc_intermediate_5.set_index('portfolio').at['faangmula index', 'average daily return']) / lc_intermediate_6.set_index('portfolio').at[f'{portfolio}', 'standard deviation']\n",
    "    faangmula_sharpes.append(faangmula_sharpe)\n",
    "lc_intermediate_7 = pd.concat([lc_intermediate_6, pd.DataFrame(faangmula_sharpes)], axis = 1).rename({0: 'faangmula sharpe ratio'}, axis = 1)\n",
    "lc_intermediate_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_returns = []\n",
    "for portfolio in low_correlation_faangmula_original['portfolio']:\n",
    "    cumulative_return = (1 + faangmula_daily_returns[f'{portfolio}']).cumprod()\n",
    "    cumulative_returns.append(cumulative_return)\n",
    "\n",
    "cumulative_returns_df = pd.DataFrame(cumulative_returns)\n",
    "cumulative_returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_intermediate_7.plot(kind = 'barh', x = 'portfolio', y = 'faangmula index correlation', xlabel = '', ylabel = 'Correlation Coefficient', figsize = (20, 10), title = 'Correlations Against FAANGMULA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_intermediate_7.plot(kind = 'barh', x = 'portfolio', y = 'zero sharpe ratio', xlabel = '', ylabel = 'Sharpe Ratio Against Zero Return', figsize = (20, 10), title = 'Sharpe Ratios Against Zero Return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#import questionary\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinapi_data(tickers):\n",
    "   \n",
    "    headers = {'X-CoinAPI-Key' : 'DABB5DFC-447C-4F57-8600-147722F5C7BA'}\n",
    "\n",
    "    coinapi_data = {}\n",
    "    for ticker in tickers:\n",
    "        url = f'https://rest.coinapi.io/v1/exchangerate/{ticker}/USD/history?period_id=1DAY&time_start=2019-01-01T00:00:00&time_end=2022-04-10T00:00:00&limit=900'\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        print(json.loads(response.content))\n",
    "        ticker_data = pd.DataFrame(json.loads(response.content))\n",
    "\n",
    "        #ticker_data['symbol'] = ticker\n",
    "        ticker_data = ticker_data.rename(columns = {'time_period_end': 'timestamp', 'rate_close': 'close'})\n",
    "        ticker_data = ticker_data.drop(['time_period_start', 'time_open', 'time_close', 'rate_open', 'rate_high', 'rate_low'], axis=1).reset_index()\n",
    "        ticker_data = ticker_data.set_index('timestamp')\n",
    "        coinapi_data[ticker] = ticker_data\n",
    "\n",
    "        time.sleep(3)\n",
    "        \n",
    "    return coinapi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['BTC', 'ETH', 'LUNA', 'SOL', 'XRP', 'ADA', 'AVAX', 'DOT', 'DOGE', 'SHIB', 'MATIC', 'DAI', 'LTC', 'ATOM', 'LINK', 'UNI', 'TRX', 'BCH']\n",
    "#two_tickers = ['BTC', 'ETH']\n",
    "crypto_original = coinapi_data(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_original = pd.concat(crypto_original.values(), keys = crypto_original.keys(), axis = 'columns')\n",
    "crypto = crypto_original.xs('close', level = 1, axis = 'columns')\n",
    "crypto.index = crypto.index.astype('datetime64[ns]')\n",
    "crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto.to_csv('./crypto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_close = pd.concat([faangmula, crypto], axis = 1, join = 'outer')\n",
    "all_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cb427dff5aded50a6174136f2d0ef82a92165ffe95fdd0ee038700b85e6fa72"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
